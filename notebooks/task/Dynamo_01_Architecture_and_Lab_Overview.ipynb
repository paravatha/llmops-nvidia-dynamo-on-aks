{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"./images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 NVIDIA Dynamo: Lab Infrastructure, Dynamo and Monitoring Setup\n",
    "\n",
    "In this comprehensive notebook, you'll first gain a deep understanding of NVIDIA Dynamo's architecture, core concepts, and the innovations that make it a powerful framework for high-performance inference deployment. Then, you'll explore the production-grade lab infrastructure where you'll deploy and experiment with Dynamo in real-world scenarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "## 1.1 Lab Infrastructure\n",
    "- [Cluster Overview](#21-cluster-overview)\n",
    "- [GPU Resource Management](#22-gpu-resource-management)\n",
    "- [Monitoring Setup](#23-monitoring-setup)\n",
    "  - [DCGM Exporter](#231-dcgm-exporter)\n",
    "  - [Prometheus & Grafana](#232-prometheus--grafana)\n",
    "  - [Dashboard Configuration](#233-dashboard-configuration)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The lab environment is designed to mirror real-world AI production setups, providing hands-on experience with the same technologies and patterns used in enterprise deployments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Lab Infrastructure\n",
    "\n",
    "NVIDIA Dynamo is designed around several key architectural principles that address the unique challenges of serving large language models (LLMs) and generative AI workloads at scale.\n",
    "\n",
    "### Why This Infrastructure Matters for Dynamo\n",
    "\n",
    "The architectural principles you learned about Dynamo - disaggregated serving, intelligent scheduling, and multi-tier memory management - all require a sophisticated orchestration platform. Kubernetes provides:\n",
    "\n",
    "- **Dynamic Resource Allocation**: Essential for Dynamo's adaptive planning\n",
    "- **Multi-Node Coordination**: Required for disaggregated prefill/decode operations\n",
    "- **GPU Resource Management**: Critical for Dynamo's performance optimizations\n",
    "- **Service Discovery**: Needed for LLM-aware request routing\n",
    "\n",
    "### Infrastructure Overview\n",
    "\n",
    "The cluster is built on Azure Kubernetes Service (AKS) and features a multi-node architecture optimized for AI/ML workloads. It includes:\n",
    "\n",
    "<img src=\"images/dynamo//aks.png\" style=\"float: right; width: 500px;\">\n",
    "\n",
    "1. **Default Node Pool (CPU Node)**:\n",
    "   - Handles general-purpose and lightweight CPU-based tasks\n",
    "   - Manages cluster operations and non-GPU workloads\n",
    "   - Always active as the baseline compute resource\n",
    "   - Perfect for Dynamo's control plane components\n",
    "\n",
    "2. **H100 Node Pool**:\n",
    "   - Configured with [`Standard_NC40ads_H100_v5`](https://learn.microsoft.com/en-us/azure/virtual-machines/ncads-h100-v5) instances\n",
    "   - Powered by NVIDIA H100 NVL GPUs\n",
    "   - Ideal for large-scale AI training and high-performance inference\n",
    "   - Features 94GB of GPU memory per device\n",
    "   - Where Dynamo's prefill and decode workloads will run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available nodes in the cluster\n",
    "!kubectl get nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Dynamo Deployment Overview\n",
    "\n",
    "The Dynamo Cloud Platform deployment consists of two main phases:\n",
    "1. **CRD Installation**: Deploy the core Dynamo CRDs\n",
    "2. **Platform Installation**: Deploy the core Dynamo infrastructure ( Operator, ETCD, NATS)\n",
    "\n",
    "### Deployment Method\n",
    "\n",
    "Use pre-built Helm charts and container images from NGC (recommended for production)\n",
    "```\n",
    "helm fetch https://helm.ngc.nvidia.com/nvidia/ai-dynamo/charts/dynamo-crds-{RELEASE_VERSION}.tgz\n",
    "helm fetch https://helm.ngc.nvidia.com/nvidia/ai-dynamo/charts/dynamo-platform-{RELEASE_VERSION}.tgz\n",
    "```\n",
    "\n",
    "In this lab, we have already deployed the Dynamo version `0.5.0` (https://github.com/ai-dynamo/dynamo/releases/tag/v0.5.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Namespace where Dynamo Cloud Platform will be deployed\n",
    "NAMESPACE = \"dynamo-cloud\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dynamo Platform Helm chart deploys several critical components:\n",
    "\n",
    "1. **Dynamo Operator**: The core controller that manages Dynamo resources\n",
    "2. **ETCD**: Distributed key-value store for configuration and state management\n",
    "3. **NATS**: High-performance messaging system for inter-component communication\n",
    "4. **RBAC Resources**: Service accounts, roles, and bindings for security\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Dynamo Pod Status Verification\n",
    "Expected pods:\n",
    "```\n",
    "NAME                                                              READY   STATUS      RESTARTS   AGE\n",
    "dynamo-platform-dynamo-operator-controller-manager-dc759d4xsh9t   2/2     Running     0          35m\n",
    "dynamo-platform-etcd-0                                            1/1     Running     0          27m\n",
    "dynamo-platform-etcd-pre-upgrade-n5xr4                            0/1     Completed   0          27m\n",
    "dynamo-platform-nats-0                                            2/2     Running     0          27m\n",
    "dynamo-platform-nats-box-768ddb656d-xqjr5                         1/1     Running     0          35m\n",
    "\n",
    "```\n",
    "   Status should show 'Running' for all pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get pods -n $NAMESPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Dynamo Service Status Verification\n",
    "\n",
    "```\n",
    "NAME                            TYPE        CLUSTER-IP        EXTERNAL-IP   PORT(S)             AGE\n",
    "dynamo-platform-etcd            ClusterIP   192.168.100.197   <none>        2379/TCP,2380/TCP   36m\n",
    "dynamo-platform-etcd-headless   ClusterIP   None              <none>        2379/TCP,2380/TCP   36m\n",
    "dynamo-platform-nats            ClusterIP   192.168.100.116   <none>        4222/TCP            36m\n",
    "dynamo-platform-nats-headless   ClusterIP   None              <none>        4222/TCP,8222/TCP   36m\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get services -n $NAMESPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Dynamo and Kubernetes Cluster Monitoring\n",
    "We have already installed monitoring as part of this Lab. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1.3.1 DCGM \n",
    "A comprehensive suite providing active GPU health monitoring, diagnostics, system alerts, and governance policies for GPU clusters\n",
    "\n",
    "The **DCGM Exporter** is a critical component for GPU observability in Kubernetes environments. It serves as the bridge between NVIDIA's Data Center GPU Manager (DCGM) and your monitoring stack.\n",
    "\n",
    "##### Key Capabilities:\n",
    "- **GPU Telemetry Collection**: Gathers comprehensive GPU metrics from DCGM\n",
    "- **Prometheus Integration**: Exposes metrics in Prometheus-compatible format\n",
    "- **Kubernetes Native**: Leverages KubeletPodResources API for optimal integration\n",
    "- **Real-time Monitoring**: Provides continuous GPU performance and health data\n",
    "- \n",
    "##### Architecture Overview:\n",
    "\n",
    "<center><img  src=\"images/gpu-telemetry.png\"></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check DCGM deployed as part of gpu-operator\n",
    "!kubectl get pods -n gpu-operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Prometheus and Grafana\n",
    "\n",
    "**Prometheus** is an industry-standard open-source monitoring system designed for reliability and scalability. \n",
    "In our GPU monitoring architecture, Prometheus performs several key functions. It scrapes metrics from instrumented applications and exporters It stores all scraped samples locally and runs rules over this data to either aggregate and record new time series from existing data or generate alerts. Prometheus targets represent how Prometheus extracts metrics from a different resources. In many cases, the metrics are exposed by the services themselves, such as Kubernetes. In this case, Prometheus collects metrics directly. But in some instances, like in unexposed services, Prometheus has to use exporters. Exporters are some programs that extract data from a service and then convert them into Prometheus formats.\n",
    "\n",
    "<center><img src=\"images/k8s/prometheus-architecture.png\" width=\"700\"></center>\n",
    "\n",
    "\n",
    "**[Grafana](https://grafana.com/)**: Advanced visualization platform for creating rich, interactive dashboards and alerts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check the status of Prometheus and Grafana. Initially, you may see pods in `ContainerCreating` status, which will transition to `Running` as they initialize.\n",
    "\n",
    "**Expected Components:**\n",
    "- **Grafana**: Web-based visualization platform\n",
    "- **Prometheus Operator**: Manages Prometheus instances\n",
    "- **Kube State Metrics**: Kubernetes metrics collector\n",
    "- **Node Exporter**: Host-level metrics exporter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Output \n",
    "```\n",
    "NAME                                                        READY   STATUS    RESTARTS   AGE\n",
    "alertmanager-kube-prometheus-stack-alertmanager-0           2/2     Running   0          41m\n",
    "kube-prometheus-stack-grafana-dc596f6f7-5b4kg               3/3     Running   0          41m\n",
    "kube-prometheus-stack-kube-state-metrics-8655798c4c-zxc7t   1/1     Running   0          41m\n",
    "kube-prometheus-stack-operator-6dc4bf67dd-rjn8j             1/1     Running   0          41m\n",
    "kube-prometheus-stack-prometheus-node-exporter-2m9gr        1/1     Running   0          41m\n",
    "prometheus-kube-prometheus-stack-prometheus-0               2/2     Running   0          41m\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get pods  -n prometheus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2.1 Expose Prometheus Service\n",
    "\n",
    "##### Prometheus Service Access\n",
    "\n",
    "To interact with the Prometheus metrics database and query interface, we need to expose the Prometheus service for external access. We'll use port forwarding to make the Prometheus UI available on your lab instance.\n",
    "\n",
    "**Port Forwarding Setup:**\n",
    "- **Local Port**: 30090 (accessible from your browser)\n",
    "- **Target Port**: 9090 (Prometheus server default)\n",
    "- **Access Method**: Direct connection to Prometheus service\n",
    "\n",
    "This will enable you to query GPU metrics, explore DCGM data, and validate the monitoring pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the Prometheus service name\n",
    "PROM_NAME = !kubectl get svc --namespace prometheus -l app=kube-prometheus-stack-prometheus -o custom-columns=NAME:.metadata.name --no-headers\n",
    "PROM_NAME = PROM_NAME[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Port forward\n",
    "import subprocess\n",
    "\n",
    "subprocess.Popen(\n",
    "    [\n",
    "        \"kubectl\",\n",
    "        \"-n\",\n",
    "        \"prometheus\",\n",
    "        \"port-forward\",\n",
    "        \"--address\",\n",
    "        \"0.0.0.0\",\n",
    "        f\"service/{PROM_NAME}\",\n",
    "        \"30090:9090\",\n",
    "    ],\n",
    "    stdout=subprocess.DEVNULL,\n",
    "    stderr=subprocess.DEVNULL,\n",
    "    close_fds=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prometheus UI Access\n",
    "\n",
    "The Prometheus interface is now accessible through port forwarding. You can use the Prometheus Query UI to explore GPU metrics, validate data collection, and understand your system's performance characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Open Prometheus!](/prom/graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2.2 Configure Grafana Access\n",
    "\n",
    "##### Grafana Dashboard Access\n",
    "\n",
    "Now we'll configure access to the Grafana visualization platform. Similar to Prometheus, we'll use port forwarding to make Grafana available through your lab instance's web interface.\n",
    "\n",
    "**Access Configuration:**\n",
    "- **Local Port**: 31091 (matches our NodePort configuration)\n",
    "- **Target Port**: 80 (Grafana web interface)\n",
    "- **Authentication**: Username `admin`, Password `prom-operator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the Grafana service name\n",
    "GRAFANA_NAME = !kubectl get svc --namespace prometheus -l app.kubernetes.io/name=grafana -o custom-columns=NAME:.metadata.name --no-headers\n",
    "GRAFANA_NAME = GRAFANA_NAME[0]\n",
    "# Port forward\n",
    "import subprocess\n",
    "\n",
    "subprocess.Popen(\n",
    "    [\n",
    "        \"kubectl\",\n",
    "        \"-n\",\n",
    "        \"prometheus\",\n",
    "        \"port-forward\",\n",
    "        \"--address\",\n",
    "        \"0.0.0.0\",\n",
    "        f\"service/{GRAFANA_NAME}\",\n",
    "        \"31091:80\",\n",
    "    ],\n",
    "    stdout=subprocess.DEVNULL,\n",
    "    stderr=subprocess.DEVNULL,\n",
    "    close_fds=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Grafana interface is now exposed. Let's open the Grafana Dashboard.\n",
    "\n",
    "To login, use: \n",
    "- Username: `admin` \n",
    "- Password: `prom-operator` \n",
    "\n",
    "The password was originally set in the `kube-prometheus-stack.values` file. If successful, your page should look similar to this:\n",
    "\n",
    "<center><img src=\"images/k8s/grafana_page1.png\" style=\"width: 800px\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Open Grafana!](/grafana/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU Telemetry Dashboard Setup\n",
    "\n",
    "Now let's create a comprehensive GPU monitoring dashboard using a pre-built template optimized for NVIDIA GPUs and DCGM metrics.\n",
    "\n",
    "**Dashboard Import Process:**\n",
    "\n",
    "1. **Navigate to Import**: In Grafana, select the \"+\" icon → \"Import\" from the left sidebar\n",
    "2. **Load Dashboard Template**: Enter the dashboard ID: `https://grafana.com/grafana/dashboards/12239`\n",
    "3. **Configure Data Source**: Select \"Prometheus\" as the data source in the dropdown\n",
    "4. **Customize Settings**: Adjust dashboard name and folder location if desired\n",
    "5. **Import Dashboard**: Click \"Import\" to create your GPU monitoring dashboard\n",
    "\n",
    "<center><img src=\"images/grafana.png\" style=\"width: 800px\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 Configure Dynamo Monitoring\n",
    "\n",
    "#### Dynamo Component Monitoring\n",
    "\n",
    " The Dynamo platform exposes metrics that provide insights into:\n",
    "\n",
    "- **Inference Performance**: Request latency, throughput, and queue depths\n",
    "- **Resource Utilization**: CPU, memory, and GPU usage across components  \n",
    "- **System Health**: Component availability, error rates, and resource limits\n",
    "\n",
    "#### PodMonitor Configuration\n",
    "\n",
    "Dynamo components expose Prometheus metrics through standard `/metrics` endpoints. We have configured PodMonitor resources to automatically discover and scrape these metrics.\n",
    "\n",
    "The PodMonitor resources target specific Dynamo components:\n",
    "- **Frontend**: Request routing and load balancing metrics\n",
    "- **Prefill Workers**: Input processing performance metrics\n",
    "- **Decode Workers**: Token generation and KV cache metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample Output\n",
    "```\n",
    "NAMESPACE    NAME                            AGE\n",
    "prometheus   dynamo-decode-worker-metrics    46m\n",
    "prometheus   dynamo-frontend-metrics         46m\n",
    "prometheus   dynamo-prefill-worker-metrics   46m\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get podmonitors -A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View the Dashboard\n",
    "- Navigate to **Dashboards → Dynamo Dashboard**.\n",
    "- Open your newly imported dashboard.\n",
    "- You should now see real-time metrics from your cluster.\n",
    "\n",
    "[Open Grafana!](/grafana/) -> Dynamo Dashboard\n",
    "\n",
    "<center><img src=\"images/dynamo-grafana-dashboard.png\" width=\"700px\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this comprehensive notebook, you've learned about both NVIDIA Dynamo's innovative architecture and the production-grade infrastructure where you'll deploy and experiment with these concepts.\n",
    "\n",
    "### Key Takeaways from Dynamo Architecture:\n",
    "\n",
    "1. **Disaggregated Serving**: Separating prefill and decode operations for optimal resource utilization\n",
    "2. **KV Cache Management**: Multi-tier cache management with 40% TTFT improvements\n",
    "3. **LLM-Aware Routing**: Intelligent request routing that understands LLM workload characteristics\n",
    "4. **Dynamic Planning**: Both load-based and SLA-based planning for different use cases\n",
    "5. **NIXL**: Accelerated data transfer across memory hierarchies\n",
    "6. **Performance Benefits**: Significant improvements in latency, throughput, and resource efficiency\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "Now that you understand both Dynamo's architecture and the infrastructure capabilities, and the Dynamo Cloud Platform is already running - next step is deploy Dynamo Infernece Graphs.\n",
    "\n",
    "**Continue to**: [vLLM Agg Deployment](Dynamo_02_vLLM_Agg_Deployment.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"./images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
